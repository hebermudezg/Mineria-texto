{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de archivos a cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminos = [\"ciencia de datos.txt\",  \"machine learning.txt\", \"aprendizaje automatico.txt\",  \"big data.txt\",\n",
    "            \"inteligencia artificial.txt\", \"analitica de datos.txt\", \"mineria de datos.txt\",\n",
    "            \"inteligencia de negocios.txt\", \"estadistica.txt\", \"aprendizaje estadistico.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion que permite integrar todo lo que es el escrapig automatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_pages(text_document):\n",
    "    text = open(text_document, 'r').read()\n",
    "    links = re.findall(r'https.+', text)\n",
    "    textos = dict()\n",
    "    for j in links:\n",
    "        try:\n",
    "            page_response = requests.get(j, timeout=25)\n",
    "            page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "            max_ = len(page_content.find_all(\"p\"))\n",
    "            textContent = []\n",
    "            for i in range(0, max_):\n",
    "                paragraphs = page_content.find_all(\"p\")[i].text\n",
    "                textContent.append(paragraphs)\n",
    "            textos[j] = textContent\n",
    "        except:\n",
    "            pass\n",
    "    textos = textos.items()\n",
    "    return textos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = [\"ciencia_de_datos\",  \"machine_learning \", \"aprendizaje_automatico \",  \"big_data \",\n",
    "            \"inteligencia_artificial \", \"analitica_de_datos \", \"mineria_de_datos \",\n",
    "            \"inteligencia_de_negocios \", \"estadistica\", \"aprendizaje_estadistico\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos = dict(scraping_pages(terminos[0]))\n",
    "\n",
    "machine_learning = dict(scraping_pages(terminos[1]))\n",
    "\n",
    "aprendizaje_automatico =  dict(scraping_pages(terminos[2]))\n",
    "\n",
    "big_data =  dict(scraping_pages(terminos[3]))\n",
    "\n",
    "inteligencia_artificial =  dict(scraping_pages(terminos[4]))\n",
    "\n",
    "analitica_de_datos =  dict(scraping_pages(terminos[5]))\n",
    "\n",
    "mineria_de_datos =  dict(scraping_pages(terminos[6]))\n",
    "\n",
    "inteligencia_de_negocios =  dict(scraping_pages(terminos[7]))\n",
    "\n",
    "estadistica =  dict(scraping_pages(terminos[8]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mineria de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concatenar(fuente):\n",
    "    conc = []\n",
    "    for k,v in fuente.items():\n",
    "        conc = v + conc\n",
    "    return conc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos1 = concatenar(ciencia_de_datos)\n",
    "\n",
    "machine_learning1 = concatenar(machine_learning)\n",
    "\n",
    "aprendizaje_automatico1 =  concatenar(aprendizaje_automatico)\n",
    "\n",
    "big_data1 =  concatenar(big_data)\n",
    "\n",
    "inteligencia_artificial1 =  concatenar(inteligencia_artificial)\n",
    "\n",
    "analitica_de_datos1 =  concatenar(analitica_de_datos)\n",
    "\n",
    "mineria_de_datos1 = concatenar(mineria_de_datos)\n",
    "\n",
    "inteligencia_de_negocios1 =  concatenar(inteligencia_de_negocios)\n",
    "\n",
    "estadistica1 =  concatenar(estadistica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos1 = ' '.join(ciencia_de_datos1)\n",
    "\n",
    "machine_learning1 = ' '.join(machine_learning1)\n",
    "\n",
    "aprendizaje_automatico1 =  ' '.join(aprendizaje_automatico1)\n",
    "\n",
    "big_data1 =  ' '.join(big_data1)\n",
    "\n",
    "inteligencia_artificial1 =  ' '.join(inteligencia_artificial1)\n",
    "\n",
    "analitica_de_datos1 =  ' '.join(analitica_de_datos1)\n",
    "\n",
    "mineria_de_datos1 =  ' '.join(mineria_de_datos1)\n",
    "\n",
    "inteligencia_de_negocios1 =  ' '.join(inteligencia_de_negocios1)\n",
    "\n",
    "estadistica1 =  ' '.join(estadistica1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIBM\\n\\n\\n\\n\\n\\n\\n \\n¿Desea añadir la IA en su empresa? Descubra cómo implementar modelos más rápido.\\n \\nPlanifique una Consulta Gratuita\\n\\nVea la demo (13:17)\\n\\n Su equipo de ciencia de datos puede ayudar a varios departamentos, utilizando un conjunto diverso de herramientas y técnicas disponibles en IBM Data Science Platform. En esta demostración, descubra cómo la ciencia de datos ayuda a escalar modelos predictivos, prediciendo la implementación de los ajustadores y las reclamaciones fraudulentas. Usted obtendrá:  Léalo ahora\\n Prediga con confianza lo que sucederá a continuación para lograr decisiones más inteligentes para su organización. IBM es líder en plataformas de ciencia de datos.  Conozca más\\n IBM tiene una de las plataformas líderes en ciencia de datos, permitiéndole colaborar fácilmente entre equipos, utilizar las herramientas de código abierto y escalar a la velocidad que su empresa necesita.  Conozca más\\n Ayude a las organizaciones a tomar mejores decisiones resolviendo problemas complejos de optimización que impliquen trade-offs entre los objetivos del negocio y sus limitaciones.  Conozca más\\n Por Carlo Appugliese@CAppugliese Mientras que la ciencia de datos y la inteligencia artificial son relativamente nuevas en el mercado, el concepto de extraer valor de los datos ya está más asentado. Pero el tiempo ha cambiado las cosas y los directores están tratando con diversas herramientas (opciones de código abierto con Rand Python y paquetes propietarios, como SAS y SPSS), habilidades y técnicas (machine learning, optimización, estadísticas y otras), así como diversas opciones de carga de trabajo que tratan con grandes volúmenes de datos (EDW, Hadoop y otras). Dirigir equipos de ciencia de datos no es una tarea fácil y muchos se preguntan cómo pueden maximizar su valor comercial actualmente. Carlo Appugliese comparte los insights clave de las experiencias de su equipo para ayudar a cientos de compañías a mejorar sus prácticas de la ciencia de datos, desde cómo reducir el tiempo al impacto hasta cómo conseguir el mejor trabajo de su equipo. Carlo comparte seis pasos para dirigir un equipo de DS efectivo: Los capítulos incluyen:  Obtenga una copia gratuita\\n Escuche a los directores de ciencia de datos, analítica y negocios en Revelwood, QueBit y Liberty Seguros en este video de muestra. \\n\\nVea el vídeo\\n\\n  Regresión lineal\\n  Regresión logística\\n  Modelo de optimización\\n  Software de optimización\\n  Diseño de ciencia de datos\\n  Ciencia de datos y código abierto\\n  Introducción a las herramientas de ciencia de datos en Bluemix\\n \\nVisit us on Facebook\\nVisit us on Twitter\\nVisit us on LinkedIn\\nVisit us on YouTube\\n Ahora todo es llamado “big data” y “ciencia de datos”. El problema es que no contamos con definiciones claras y comprobables. Se han realizado intentos para definir estos conceptos, en el caso de big data acostumbra mencionarse a las 3 Vs (volumen, variedad y velocidad), y en el caso de la ciencia de datos es común encontrarse con este diagrama.  El problema es que estas definiciones son abiertas; nombran algunos ejemplos (como el volumen), pero esencialmente dejan abierta la posibilidad de llamar cualquier cosa “big data” o “ciencia de datos”. Esto no es de sorpender, ya que a fin de cuentas son términos creados con propósitos de marketing. Si alguna vez queremos llegar a una definición utilizable y deshacernos de todo el despliegue publicitario, debemos considerar una definición más precisa, inclusive cuando esto signifique hacerlo más exclusivo. Big Data: Ciencia de Datos: Pero todo esto está muy lejos de una definición adecuada, en parte debido al gran dinamismo que hay alrededor de estos conceptos. Hay una gran cantidad de traslape que debemos tratar de comprender. Por ejemplo, la ciencia de datos no es sólo estadística porque está mucho más preocupada por cómo se estructura la información y cómo hacer el procesamiento de datos con mayor eficiencia computacional. Sin embargo, a menudo la estadística es mucho mejor para tomar en cuenta el conocimiento del dominio. En cambio, las personas procedentes del área de computación por lo general se preocupan muy poco sobre el conocimiento del dominio y la confiabilidad de sus resultados, son felices con lograr que los datos sean procesados. Por último, pero no menos importante, pocas personas estarán a favor de una definición tan acotada y estricta. Porque esto implicaría que muchos tendrían que eliminar ese título de “científico de datos “ en su tarjeta de presentación - ¿y para qué morder la mano que nos alimenta? En mi caso, la mayor parte de lo que hago estrictamente no califica como \"big data\". Y aunque esto no disminuya el valor de mi trabajo, sí lo hace menos comercializables. Esencialmente, esto es como un “acuerdo entre caballeros“ global: explotemos estas palabras mientras podamos, y luego pasamos a las siguientes. Tal vez lo que deberíamos hacer es dejar estos términos a la gente de marketing para que los inflen hasta que exploten. En su lugar, deberíamos atenernos a los términos establecidos y mejor definidos: En fin, lo que sea que hagas, utiliza el término preciso. Por supuesto, en ocasiones tendremos que entrar en el juego del \"buzzword bingo\", no podemos evitarlo. Pero cuando podamos, seamos más precisos. También debemos ser más cuidadosos con el uso del adjetivo \"disruptivo\". Mientras lo que hagamos sea “negocios como de costumbre “, y se base en software disponible comercialmente, no va a ser disruptivo. En realidad, lo que buscan las empresas no es big data ni ciencia de datos. Lo que buscan son resultados disruptivos, lo cual requiere hacer las cosas de manera radicalmente distinta. Eric W. Schubert estudió Matemáticas y Ciencias de la Computación en la Universidad de Munich. Sus intereses están en el campo de la estructura y naturaleza de la información y el conocimiento por lo que la mayoría de sus proyectos, investigaciones\\ny temas de docencia pertenecen a dicha categoría. Software Guru es el medio preferido por las personas de habla hispana interesadas en construir software de alto desempeño. Conocimiento para construir software grandioso. La página que estás buscando no la tenemos. Carrera 50 C #10 Sur 80t: +57 (4) 605 2523Colombia Calle 99 # 13A – 30 Piso 3t: +57 (1) 745 2523\\xa0Colombia Carrera 80 # 11 A-51 Local 401 B/Caprit: +57 (2) 486 2523Colombia Ciudad del Saber,Edificio #104, Clayton, Ancón.Panamá.  La ciencia de datos es el estudio de dónde proviene la información, qué representa y cómo se puede convertir en un recurso valioso para la creación de estrategias empresariales y de TI. La extracción de grandes cantidades de datos estructurados y no estructurados para identificar patrones puede ayudar a una organización a controlar los costos, aumentar la eficiencia, reconocer nuevas oportunidades de mercado y aumentar la ventaja competitiva de la organización. El campo de la ciencia de datos emplea matemáticas, estadística y disciplinas informáticas, e incorpora técnicas como el aprendizaje automático, el análisis de conglomerados, la extracción de datos y la visualización. A medida que aumenta la cantidad de datos generados por los negocios modernos típicos, también aumenta la importancia de los científicos de datos contratados por organizaciones para ayudarlos a convertir los datos en bruto en información comercial valiosa. La extracción de datos es el acto de recuperar datos específicos de fuentes de datos no estructurados o mal estructurados para su posterior procesamiento e investigación. Los científicos de datos deben poseer una combinación de habilidades analíticas, de aprendizaje automático, de minería de datos y estadísticas, así como experiencia con algoritmos y codificación. Junto con la administración e interpretación de grandes cantidades de datos, muchos científicos de datos también tienen la tarea de crear modelos de visualización de datos que ayuden a ilustrar el valor empresarial de la información digital. Sin embargo, para ser efectivos, los científicos de datos deben poseer inteligencia emocional además de educación y experiencia en el análisis de datos. Quizás la habilidad más importante que un científico de datos debe poseer es la capacidad de presentar los conocimientos de los datos a otros, incluidos los ejecutivos de nivel directivo o C-suite, y explicar la importancia de los datos de una manera que pueda entenderse fácilmente. Los científicos de datos obtienen la información digital que están estudiando de una creciente lista de canales y fuentes, incluidos los teléfonos inteligentes, los dispositivos de internet de las cosas (IoT), las redes sociales, las encuestas, las compras, las búsquedas y el comportamiento de internet. Al clasificar estos grandes conjuntos de datos, los científicos de datos pueden identificar patrones para resolver problemas a través del análisis de datos, un proceso conocido como minería de datos. La principal ventaja de contar con la ciencia de datos en una organización es el empoderamiento y la facilitación de la toma de decisiones. Las organizaciones con científicos de datos pueden tener en cuenta las pruebas cuantificables basadas en datos en sus decisiones comerciales. Estas decisiones basadas en datos pueden, en última instancia, conducir a una mayor rentabilidad y una mayor eficiencia operativa, rendimiento de negocio y flujos de trabajo. En las organizaciones orientadas al cliente, la ciencia de datos ayuda a identificar y refinar las audiencias objetivo. La ciencia de datos también puede ayudar al reclutamiento: el procesamiento interno de aplicaciones y las pruebas de aptitud basadas en datos y los juegos pueden ayudar al equipo de recursos humanos de una organización a realizar selecciones más rápidas y precisas durante el proceso de contratación. Los beneficios específicos de la ciencia de datos varían según el objetivo de la empresa y la industria. Los departamentos de ventas y marketing, por ejemplo, pueden extraer datos de clientes para mejorar las tasas de conversión o crear campañas de marketing individuales. Las instituciones bancarias están minando datos para mejorar la detección de fraudes. Servicios de transmisión como Netflix usan la minería de datos para determinar en qué están interesados \\u200b\\u200bsus usuarios, y usar esos datos para determinar qué programas de televisión o películas producir. Los algoritmos basados \\u200b\\u200ben datos también se utilizan en Netflix para crear recomendaciones personalizadas basadas en el historial de visualización de un usuario. Compañías de envíos como DHL, FedEx y UPS utilizan la ciencia de datos para encontrar las mejores rutas y horarios de entrega, así como los mejores modos de transporte para sus envíos. La ciencia de los datos sigue siendo un campo emergente dentro de la empresa porque la identificación y el análisis de grandes cantidades de datos no estructurados puede resultar demasiado complejo, costoso y lento para las empresas. El aprendizaje automático (machine learning) se incorpora a menudo en la ciencia de datos. El aprendizaje automático es una herramienta de inteligencia artificial (IA) que esencialmente automatiza la parte de procesamiento de datos de la ciencia de datos. El aprendizaje automático integra algoritmos avanzados que aprenden por sí mismos y pueden procesar grandes cantidades de datos en una fracción del tiempo que le tomaría a un humano. Después de recopilar y procesar los datos estructurados de las herramientas de aprendizaje automático, los científicos de datos interpretan, convierten y resumen los datos para que sean útiles para los responsables de la toma de decisiones de la empresa. Las aplicaciones de aprendizaje automático utilizadas en el campo de la ciencia de datos incluyen el reconocimiento de imágenes y el reconocimiento de voz. Los algoritmos de aprendizaje automático también se están integrando en los vehículos automáticos. Marque la casilla si desea continuar. Marque la casilla si desea continuar. Todos los Derechos Reservados, \\n\\t\\t\\tTechTarget, S.A de C.V 2005 - 2019 \\n Los cursos y Programas Especializados de ciencia de datos enseñan los fundamentos para la interpretación de datos, la realización de análisis, y el entendimiento y la comunicación de información útil. Entre los temas de estudio para estudiantes principiantes y avanzados se incluyen análisis cualitativo y cuantitativo de datos, herramientas y métodos para la manipulación de datos y algoritmos de aprendizaje automático. Traducido por Carlos Secada del original por Cassie Kozyrkov (editado por Felipe Chiriboga) Aquí está mi intento más conciso: “La ciencia de datos es la disciplina de hacer que los datos sean útiles”. Siéntete libre de salir corriendo ahora, o seguir leyendo para explorar sus tres sub-campos. Si exploramos la historia del nacimiento del término ciencia de datos, veremos dos temas que se juntan. Permítanme parafrasear para su entretenimiento: Y así nace la ciencia de datos. La primera vez que escuché su definición fue “un científico de datos es un estadístico que puede programar”. Te voy a dar mi opinión sobre esta definición en un momento, pero primero, ¿por qué no examinamos qué es la ciencia de datos en sí misma? Me encanta cuando leo el Journal of Data Science del 2003, en donde hacen una definición “muy precisa” diciendo: “Por \\'Ciencia de Datos\\' queremos referirnos a casi todo lo que tiene algo que ver con los datos”. ¿En serio? ¿todo? Me es difícil pensar en algo que no tenga nada que ver con datos. (Mejor dejo de seguir pensando antes de que me empiece a doler la cabeza.) Desde entonces, hemos visto una gran cantidad de opiniones, desde el muy difundido diagrama de Venn de Conway (a continuación ) hasta la publicación clásica de Mason y Wiggins. Wikipedia tiene una definición que es muy cercana a la que les enseño a mis alumnos:\\nLa ciencia de datos es un “concepto para unificar estadísticas, análisis de datos, Machine Learning y sus métodos relacionados”, para “entender y analizar fenómenos reales” con datos. No está nada mal, pero veamos si lo puedo poner aún más sencillo: “La ciencia de datos es la disciplina de hacer que los datos sean útiles.” Pueda que ahora estés pensando: “Buen intento. Está bonito, pero es una extraordinariamente mala sobre-simplificación. ¿Cómo así la palabra ‘útil’ puede capturar todo el significado del concepto? ”\\nBueno, está bien, vamos a discutirlo con fotos. ¿Qué son estas cosas y cómo saber en qué parte del mapa estamos? La diferencia entre un estadístico y un ingeniero de Machine Learning (ML) no es que uno programe en R y el otro en Python. La clasificación de SQL vs R vs Python es tonta por muchas razones, entre las cuales está que el software evoluciona. (Actualmente, incluso puedes hacer ML en SQL). ¿No preferirías una clasificación que perdure en el tiempo? Si es así, simplemente continúa leyendo y haz de cuenta que no leíste nada de este párrafo. Tal vez sea aún peor la forma favorita de clasificarla de los novatos. Sí, lo has adivinado: lo hacen por algoritmos (¡sorpresa! Es cómo se estructuran los cursos universitarios). Por favor, por favor, no lo clasifiquen por histogramas vs t-tests vs redes neuronales. En realidad, si uno es inteligente y tiene claro el punto que quiere demostrar, puede usar casi el mismo algoritmo para cualquier parte de la ciencia de datos. \\nBueno, ¡basta ya de darle vueltas! Aquí está la clasificación que propongo: ¿De qué diablos se trata es esto? ¡De Decisiones, por supuesto! ¿No era obvio? Uy, perdón por no ser clara… (Bajo información incompleta, cuando todos los datos que necesitas son visibles, puedes usar analítica descriptiva para tomar tantas decisiones como desees. Solo mira los hechos y listo). Es a través de nuestras acciones — nuestras decisiones — que afectamos el mundo que nos rodea. Prometí que iba a hablar sobre cómo hacer que los datos sean útiles. Para mí, la idea de utilidad está estrechamente relacionada con influir en las acciones del mundo real. Si yo creo en Papá Noel, realmente no importará hasta que esa creencia pueda influir de alguna manera en mi comportamiento. Luego, dependiendo de las posibles consecuencias de mi comportamiento, podría comenzar a importar muchísimo. Es a través de nuestras acciones, nuestras decisiones, que afectamos el mundo que nos rodea (y hacemos que nos afecte a nosotros también).\\nAsí que aquí está una nueva imagen completamente orientada a la toma de decisiones, con las tres formas principales de hacer que tus datos sean útiles. Si aún no sabes qué decisiones quieres tomar, lo mejor que puedes hacer es salir en busca de inspiración para poderlas descubrir. Esto se conoce como análisis de datos o analítica o analítica descriptiva o análisis de datos exploratorio (EDA en inglés) o descubrimiento del conocimientos (KD en inglés), dependiendo de gustos y colores. Y contrario a lo que dice el refrán, de esto si han escrito mucho los autores. Regla de oro de la analítica: solo saca conclusiones de lo que puedes ver. Comienza aquí, a menos que ya sepas cómo estructurar tu toma de decisiones. La buena noticia es que esto es fácil. Piensa en tu conjunto de datos como un grupo de fotos en negativo que las encontraste en un cuarto oscuro de revelado. La extracción de datos consiste en utilizar los equipos para revelar las fotos lo más rápido posible, para que puedas ver si hay algo inspirador o interesante en ellas. Al igual que con las fotos, recuerda no tomarte en serio lo que ves. Tú no tomaste las fotos, así que no sabes mucho sobre las historias que hay detrás de ellas. La regla de oro de la minería de datos es: enfocarse en lo que está aquí. Solo saca conclusiones acerca de lo que puedes ver, nunca a cerca de lo que no puedes ver (para eso necesitas estadísticas y mucha más experiencia). La experiencia en minería de datos es juzgada por la velocidad con la que puedes examinar los datos. El cuarto oscuro de revelado es intimidante al principio, pero no se puede hacer mucho al respecto. Solo aprender a utilizar bien el equipo de revelado. Aquí hay un tutorial en R y aquí en Python para comenzar. Puedes llamarte a ti mismo un “analista de datos” tan pronto como empieces el trabajo, y puedes llamarte un “analista experto” cuando puedas revelar las fotos (y todos los demás tipos de conjuntos de datos) a la velocidad de un rayo. La inspiración es barata, pero el rigor es caro. Si quieres llegar más lejos con los datos, necesitarás capacitación especializada. Teniendo yo un bachillerato y posgrado en estadística, pueda que mi opinión esté un poco parcializada, pero creo que la inferencia estadística (las estadísticas para abreviar) es de las tres áreas, la más difícil y cargada de filosofía. Llegar a ser bueno en esto, lleva más tiempo. La inspiración es barata, pero el rigor es caro. Si quieres tomar decisiones importantes, de alta calidad, y con riesgo controlado, que se basen en conclusiones sobre el mundo más allá de los datos disponibles, tendrás que agregar habilidades estadísticas a tu equipo. Un buen ejemplo es el momento en el que tu dedo está dando vueltas alrededor del botón de inicio de un sistema de Inteligencia Artificial (AI) y te viene a mente que debes verificar que funcione correctamente antes de apretarlo (siempre es una buena idea, en serio). Aléjate del botón y llama al estadístico. La estadística es la ciencia de cambiar tu mente (cuando hay incertidumbre). Si quieres saber más al respecto, he escrito este super-resumen de estadística de 8 minutos para que lo disfrutes. El Machine Learning consiste esencialmente en hacer recetas para etiquetar cosas utilizando ejemplos en lugar de instrucciones . He escrito algunas publicaciones al respecto, incluyendo si ML es diferente de AI, cómo comenzar con ML, por qué las empresas fallan en ML y el primer par de artículos de una serie de artículos escritos en lenguaje sencillo sobre toda esta jerga (empieza aquí ). Ah, y si quieres compartirlo con amigos que no hablen inglés, un montón de ellos están traducidos aquí. ¿Qué hay de la ingeniería de datos, que es el primero en entregar datos al equipo de ciencia de datos? Como es un campo sofisticado, prefiero protegerlo de las aspiraciones hegemónicas de la ciencia de datos y además, está mucho más cerca de la ingeniería de software que de las estadísticas. La diferencia entre la ingeniería de datos y la ciencia de datos es la diferencia del antes y el después. Siéntete libre de ver la diferencia entre la ingeniería de datos y la ciencia de datos como un antes y después. La mayor parte del trabajo técnico que conduce al nacimiento de los datos (antes) puede llamarse “ingeniería de datos” y todo lo que hacemos cuando llegan algo de datos (después) es “ciencia de datos”. DI tiene que ver con decisiones, incluida la toma de decisiones a escala con datos, lo que la convierte en una disciplina de ingeniería. Amplía la aplicación de la ciencia de datos con las ideas de las ciencias sociales y de gestión. La inteligencia de decisiones agrega componentes de las ciencias sociales y de gestión. En otras palabras, es un super conjunto de esos pedazos de la ciencia de datos que no se ocupan de cosas de investigación, tales como la creación de metodologías fundamentales para uso general.\\n¿Te quedaste con hambre? Aquí hay un detalle de los roles en un proyecto de ciencia de datos para que te entretengas mientras termino de hacer clic en mi teclado. Obtenga más información sobre ciencia de datos e inteligencia artificial en español aquí. Written by Suscríbete a Xataka Recibe un email al día con nuestros artículos:  \\nSuscribir La sabiduría popular lo tiene claro, un científico de datos (un data scientist) es \"un estadístico que trabaja en San Francisco\". Y es que, desde hace unos años, esta profesión está de moda gracias, en parte, al mundo startupil. Pero la ciencia de datos va mucho más allá y está convirtiéndose en una de las profesiones más prometedoras de hoy en día. La fiebre de los datos ha hecho que empecemos a escuchar hablar de esta disciplina por todos lados. Pero, no podemos dejar de preguntarnos si es una moda pasajera o los científicos de datos han venido para quedarse. Repasamos qué es exactamente eso de la data science, sus oportunidades laborales y las posibilidades que existen para formarse. \\n\\n\\n \\n\\n\\n Otra forma de verlo es la de Josh Wills. Wills usa otra definición que me parece mucho más acertada e intuitiva: \"Científico de datos (n): Persona que sabe más de estadística que cualquier programados y que a la vez sabe más de programación que cualquier estadístico\". Un poco más en serio, un científico de datos es sencillamente un profesional dedicado a analizar e interpretar grandes bases de datos. O lo que es lo mismo, uno de los profesionales más importantes en cualquier empresa de internet hoy en día. La respuesta nos la daba Javi Pastor: la tecnología actual no solo necesita del mejor talento sino de datos, mucho datos. Muchos. Es decir, que la moda por lo abierto y el giro hacia los datos no es más que la enésima máscara del mismo espíritu corporativo de siempre buscando el próximo yacimiento. Y lo que vale para los entornos de inteligencia artificial y de machine learning, vale para casi cualquier tecnología.   Lo curioso es que este gran valor de los datos contrasta con que precisamente los datos son el recurso más abundante del planeta (se calcula que se crean 2.5 trillones de bytes de información nuevos al día). No parecen cosas fáciles de compatibilizar. ¿Cómo es posible que algo tan abundante sea tan valioso? Aunque fuera por pura oferta y demanda, acumular datos debería ser algo trivial. Y lo es, lo complejo es procesarlos.      Hasta hace relativamente poco sencillamente no podíamos hacerlo. A finales de los años 90, el campo del machine learning (aprendizaje automático) empezó a tomar entidad autónoma, nuestra capacidad de trabajar con cantidades inmensas de datos se abarató y la irrupción social de internet hizo el resto. Desde hace unos años nos encontramos ante la primera gran \\'democratización\\' de estas técnicas. Y, con ello, el boom de los científicos de datos: nadie quiere tener una mina de oro sin aprovechar.  El problema es que, de repente, ha surgido una gran demanda de un perfil que hasta ahora prácticamente no existía. Recordemos que se precisan conocimientos estadísticos que un programador no suele tener y conocimientos informáticos que un estadístico no suele ni siquiera imaginar. La mayor parte de las veces se ha solucionado con formación autodidacta que completa las habilidades básicas que debería tener programa formativo pero no tiene. Por eso, hoy por hoy, podemos encontrar una gran diversidad de perfiles profesionales en el mundo de la ciencia de datos. Según Burtch Works, el 32% de los científicos de datos en activo vienen del mundo de las matemáticas y la estadística, el 19% de la ingeniería informática y el 16% de otras ingenierías. A día de hoy, existen algunos grados dobles en ingeniería informática y matemáticas (Autónoma de Madrid, Granada, Politécnica de Madrid, Politécnica de Cataluña, Complutense, Murcia Autónoma de Barcelona) o en informática y estadística (Universidad de Valladolid) que parecen la mejor opción si nos planteamos esta especialización. De hecho, esta opción parece más interesante que los posibles \\'grados en ciencia de datos\\' que pudieran surgir en el futuro: las posibilidades son más amplias, la formación más diversa y permite no encasillarnos. El de los posgrados es un mundo muy diverso. Podemos encontrar posgrados, másteres o cursos de especialización en casi todas las universidades y una oferta privada realmente desmesurada. Por poner algunos ejemplos tenemos posgrados en la UGR, la UAB, la UAM, la UPM o la Pompeu Fabra. De todas formas, en posgrados es más difícil recomendar un curso en concreto. La clave está en buscar complementar nuestra formación previa y, en ese sentido, la diversidad es una buena noticia.  Lo que sí podemos encontrar en la formación de posgrado que no podemos encontrar en la formación previa es el componente de \\'orientación de negocio\\'. No debemos olvidar que la mayor parte del trabajo de los científicos de datos está en empresas que buscan rentabilizar sus bases de datos, porque lo que la orientación al mercado es algo muy recomendable. De hecho, muchos de los másteres en \\'big data\\' lo ofrencen escuelas de negocios como OEI o Instituto Empresa. Uno de los recursos más interesantes que podréis encontrar son los moocs (ya sabéis, los cursos abiertos masivos online). De hecho hace poco, vimos que esta opción autoformativa podía tener mucho futuro. Empezando por el programa de especialización en big data de Coursera, podemos encontrar cursos online de las mejores universidades del mundo. Todo esto sin hablar de las numerosas herramientas para aprender lenguajes como Python o R. También existen una serie de certificados o acreditaciones que permiten avalar nuestros conocimientos en ciencia de datos: el Certified Analytics Professional (CAP), Cloudera Certified Professional: Data Scientist (CCP:DS), EMC: Data Science Associate (EMCDSA) o certificados más específicos como los de SAS. Algunos de estos certificados tienen unos requisitos muy duros pero son una buena alternativa si hemos estado trabajando en este campo con anterioridad. Otros recursos interesantes son las asociaciones (como R Hispano o Python España) y los grupos informales tipo Databeers que tanto éxito están teniendo por todo el país. Es verdad que el ecosistema de eventos y reuniones en data science está empezando a desarrollarse, pero con la experiencia acumulada en otros ámbitos seguro que se pone al día pronto. En realidad, como cualquier iniciado sabe, en programación la elección de un lenguaje u otro siempre es complicada. En esta elección intervienen desde factores técnicos o formativos a simples preferencias personales.Lo que sí está claro es que hay algunos lenguajes más populares que otros. Un insustituible La gran división  Aunque el sentido común nos dice que cada uno de los lenguajes es mejor para determinadas cosas, en la práctica hay cierta rivalidad. Personalmente, uso R pero suelo recomendar Python. No sólo porque es más bonito, sino porque es multipropósito y eso siempre es una ventaja. Un incombustible El hermano corporativo y otros lenguajes y programas Algunos lenguajes o entornos gozan de cierto éxito empujados por la inercia corporativa: es el caso del clásico Matlab pero progresivamente va perdiendo peso y uso hasta sólo un 6%. Si examinamos las encuestas podemos encontrar muchos más lenguajes que obedecen a necesidades más particulares de la práctica de los científicos de datos (o de los programas que usan): Scala (17%), Slack (10%), Perl (12%), C# (6%), Mahout (3%), Apache Hadoop (13%) o Java (23%). También, aunque es posible que debiéramos hablar de ellos por separado, hay muchos programas específicos (libres o privativos) que se usan en la ciencia de datos con distintos usos. Por poner algún ejemplo, podríamos hablar de Tableau, RapidMiner o de Weka. Los sueldos, como en general en el mundo del desarrollo de software, cambian mucho dependiendo de el lugar, las funciones y el empleador. No obstante, ahora mismo es una expertise bien pagada. A nivel general y según la encuesta anual de KdNuggets los sueldos/ingresos están en una media de 141.000 dólares para freelance, 107.000 para asalariados, 90.000 para trabajadores gubernamentales o en el sector sin ánimo de lucro; 70.000 dólares para trabajo en universidades. No obstante, estos sueldos medios hay que tomarlas con mucha prudencia. Mientras el salario medio en Estados Unidos está entre 103.000 y 131.000 dólares, en Europa Occidental está entre 54.000 y 82.000 dólares. En España, estamos en cifras similares porque, pese a nuestro (cada vez menor) déficit de empresas de producto, tenemos grandes empresas (sobre todo bancarias) que se han volcado en este campo. Lo que diferencia a la ciencia de datos del resto del mundo del desarrollo tal vez sea la escasez de profesionales. Este fenómeno hace que los sueldos estén relativamente inflados y que, conforme vayan apareciendo más perfiles dateros, se vayan ajustando. Por eso, se puede decir que es el momento para subirse a la ola de la ciencia de los datos. Dentro de un par de años el mercado habrá madurado y las oportunidades estarán en otro lugar. Imágenes | Jer Thorp, Alan Levine, Opensource, Tax Credits, yaph \\n\\n      Xataka en Instagram\\n     \\n \\nSeguir\\n Compartir Científico de datos: así es y así se forma uno en esta profesión cada vez más demandada Compartir Los mejores comentarios: Ver 34 comentarios Destacamos \\nVer más temas\\n \\nSuscribir Más sitios que te gustarán Reciente Ver más artículos  Xataka \\n     TV\\n Ver más vídeos En Xataka hablamos de... Ver más temas \\nWebedia\\n  Tecnología   Videojuegos   Entretenimiento   Gastronomía   Estilo de Vida   Motor   Economía   Familia y Ocio  Participamos en La ciencia de datos es un campo interdisciplinario que involucra métodos científicos, procesos y sistemas para extraer conocimiento o un mejor entendimiento de datos en sus diferentes formas, ya sea estructurados o no estructurados,[1]\\u200b lo cual es una continuación de algunos campos de análisis de datos como la estadística, la minería de datos, el aprendizaje automático y la analítica predictiva.[1]\\u200b\\n También se define La ciencia de datos como  \"Un concepto para unificar estadísticas, análisis de datos, aprendizaje automático y sus métodos relacionados para comprender y analizar los fenómenos reales\", [2]\\u200b  empleando técnicas y teorías extraídas de muchos campos dentro del contexto de las matemáticas, la estadística, la ciencia de la información y la informática.\\n El ganador del premio Turing, Jim Gray, imaginó la ciencia de datos como un \"cuarto paradigma\" de la ciencia (empírico, teórico, computacional y ahora basado en datos) y afirmó que \"todo lo relacionado con la ciencia está cambiando debido al impacto de la tecnología de la información y el diluvio de datos\".[3]\\u200b\\n En este nuevo paradigma, los investigadores se apoyan de sistemas y procesos que son muy diferentes a los utilizados en el pasado, como son modelos, ecuaciones, algoritmos, así como evaluación e interpretación de resultados.[1]\\u200b\\n En 1962, John W. Tukey precedió al término “Ciencia de Datos” en su artículo “The Future of Data Analysis” al explicar una evolución de la estadística matemática. En este, definió por primera vez el análisis de datos como: “Procedimientos para analizar datos, técnicas para interpretar los resultados de dichos procedimientos, formas de planificar la recopilación de datos para hacer su análisis más fácil, más preciso o acertado, y toda la maquinaria y los resultados de las estadísticas matemáticas que se aplican al análisis de datos.”[4]\\u200b En 1977 publicó “Exploratory Data Analysis”, argumentando que era necesario poner más énfasis en el uso de datos para sugerir hipótesis que probar en modelos estadísticos. \\n La ciencia de datos ha resultado para muchos una disciplina de reciente creación, pero en la realidad este concepto lo utilizó por primera vez el científico danés Peter Naur en la década de los sesenta como sustituto de las ciencias computacionales. En 1974 publicó el libro Concise Survey of Computer Methods\\n[5]\\u200b\\ndonde utiliza ampliamente el concepto ciencia de datos, lo que permitió que se comenzara a utilizar más libremente entre el mundo académico. \\n En 1977, el International Association for Statistical Computing (IASC) es establecido como una sección del International Statistical Institute (ISI). “Es la misión de la IASC relacionar la metodología estadística tradicional, tecnología computacional moderna, y el conocimiento de expertos del tema para convertir datos en información y conocimiento\".[6]\\u200b \\n En 1996 el término de Ciencia de Datos fue utilizado por primera vez en una conferencia, llamada \"Ciencia de datos, clasificación y métodos relacionados\" en una reunión de miembros de la International Federation of Classification Societies (IFCS) con sede en Kobe, Japón.[6]\\u200b En 1997, C.F. Jeff Wu dio una lectura llamada \"Statistics = Data Science?\", donde describió al trabajo estadístico como una trilogía conformada por recolección de datos, análisis y modelado de datos, y la toma de decisiones, haciendo la petición de que la estadística fuese renombrada como ciencia de datos y los estadísticos como científicos de datos.[7]\\u200b\\n En 2001, William S. Cleveland introdujo a la ciencia de datos como una disciplina independiente, extendiendo el campo de la estadística para incluir los avances en computación con datos en su artículo \"Data science: an action plan for expanding the technical areas of the field of statistics\". Cleveland estableció seis áreas técnicas que en su opinión conformarían al campo de la ciencia de datos: investigaciones multidisciplinarias, modelos y métodos para datos, computación con datos, pedagogía, evaluación de herramientas, y teoría.[8]\\u200b\\n En abril del 2002, el International Council for Science: Committee on Data for Science and Technology (CODATA) empezó la publicación del Data Science Journal,[9]\\u200b enfocada en problemas como la descripción de sistemas de datos, su publicación en Internet, sus aplicaciones y problemas legales. Poco después, en enero del 2003, la Universidad de Columbia empezó a publicar The Journal of Data Science,[10]\\u200b la cual ofreció una plataforma para que todos los profesionales de datos presentaran sus perspectivas e intercambiaran ideas.\\n En 2005, The National Science Board publicó \"Long-Lived Digital Data Collections Enabling Research and Education in the 21st Century\" definiendo a los científicos de datos como \"científicos de computación e información, programadores de bases de datos y software, expertos disciplinarios, [...] que son cruciales para la gestión exitosa de una colección digital de datos, cuya actividad primaria es realizar investigación creativa y análisis\".[11]\\u200b\\n Fue en el 2008 que Jeff Hammerbacher y DJ Patil lo reutilizaron para definir sus propios trabajos realizados en Facebook y Linkedin, respectivamente,\\n[12]\\u200b\\n En 2009, los investigadores Yangyong Zhu y Yun Xiong del Research Center for Dataology and Data Science, publicaron “Introduction to Dataology and Data Science”, en donde manifiestan que “A diferencia de las ciencias naturales y las ciencias sociales, Datología y Ciencia de Datos toman datos en la red y su objeto de estudio”.[6]\\u200b \\n En 2013 fue lanzado el IEEE Task Force on Data Science and Advanced Analytics,[13]\\u200b mientras que la primera conferencia internacional de IEEE International Conference on Data Science and Advanced Analytics fue lanzada en el 2014.[14]\\u200b En 2015, el International Journal on Data Science and Analytics fue lanzado por Springer para publicar trabajos originales en ciencia de datos y analítica de big data.[15]\\u200b\\n En septiembre de 1994, BusinessWeek publicó el artículo “Marketing de base de datos”, manifestando que las empresas recopilan una gran cantidad de información sobre los clientes, la cual es analizada para predecir la probabilidad de que compre un producto. Afirman que se utiliza ese conocimiento para elaborar un mensaje de marketing calibrado con precisión para que el individuo busque conseguirlo. Asimismo, explican que, en los ochentas, un entusiasmo provocado por la propagación de los lectores de códigos de barras terminó en una decepción generalizada pues muchas empresas fueron abrumadas por la gran cantidad de datos para lograr hacer algo útil con la información de sus clientes. Sin embargo, muchas empresas creen que no hay más remedio que desafiar la frontera marketing y bases de datos para desarrollar más las tecnologías necesarias.[16]\\u200b\\n En 2014 empresa sueca de música en streaming Spotify compra The Echo Nest, una compañía especializada en ciencia de de datos musicales. Esta ahora es la encargada de almacenar y analizar la información de sus 170 millones de usuarios.[17]\\u200b Con ayuda de dicha empresa, en 2015 Spotify lanzó un servicio de música personalizada llamado Discover Weekly que semanalmente recomienda a sus usuarios una selección de canciones que podría interesarles por medio de algoritmos y análisis de los datos de la música escuchada y el historial de búsqueda de la semana pasada. El servicio recibió una buena recepción generalizada[18]\\u200b y actualmente figura un fuerte punto de venta ante la competencia de la empresa.[19]\\u200b\\n Netflix, la empresa norteamericana de contenido multimedia en streaming ofrece a sus más de 120 millones de usuarios una plataforma capaz de analizar, mediante algoritmos, las costumbres de consumo de los usuarios para diferenciar los contenidos que estos buscan y lograr determinar qué nuevos contenidos les pueden interesar. Todd Yellin, vicepresidente de producto en Netflix, explicó que algunos de los datos almacenados pueden extenderse desde la hora del día se conectan sus usuarios, cuánto tiempo pasan dentro de la plataforma, su lista de contenidos recientemente vistos (para analizar incluso el orden específico de estos). Toda la información que se almacena es utilizada específicamente para ser analizada, aprender del usuario y poder darle recomendaciones acertadas.[20]\\u200b\\n En América Latina el Banco Interamericano de Desarrollo (BID) ha desarrollado estudios exploratorios en los que se analiza la ciencia de datos en la implementación y diseño de políticas públicas en la región, tomando casos en países como Argentina y Brasil, presentando recomendaciones para su implementación y mantenimiento.  \\n Estas van desde temas como movilidad urbana sostenible, ciudades inteligentes, seguridad, propiedad de datos y privacidad. Entre las sugerencias presentadas en las investigaciones está la de lograr una “inteligencia del valor público, la cual “tiene la potencialidad de ser un componente estratégico para la toma de decisiones y el diseño, implementación y evaluación de políticas públicas”. Otra de ellas es la capacidad para lograr desde este campo una mejora de rendición de cuentas de los gobiernos ante la ciudadanía y promover un avance en cuanto a la curaduría de datos en las instituciones públicas.[21]\\u200b\\n Textualmente, Big Data (o macrodatos) se refiere a enormes volúmenes de datos que no pueden procesarse de manera efectiva con las aplicaciones tradicionales que existen.[22]\\u200b De acuerdo con la guía de Amazon Web Service, esta considera al Big Data como a una cantidad considerable de datos con dificultades para almacenarse en bases de datos tradicionales, para procesarse en servidores estándar y para analizarse con aplicaciones habituales.\\n El término se suele relacionar con ciencia de datos, pues esta suele ser su fuente de información para análisis; La ciencia de datos logra analizar los grandes conjuntos de datos desordenados e incompletos, para llegar a hallazgos que impulsan decisiones sobre operaciones y productos.\\n Las personas que se dedican a la ciencia de datos se les conoce como científico de datos, de acuerdo con el proyecto Master in Data Science define al científico de datos como una mezcla de estadísticos, computólogos y pensadores creativos, con las siguientes habilidades:\\n El proceso que sigue un científico de datos para responder cuestiones que se le plantean se puede resumir en estos pasos:\\n El doctor en estadística Nathan Yau, precisó lo siguiente: el científico de datos es un estadístico que debería aprender interfaces de programación de aplicaciones (API), bases de datos y extracción de datos; es un diseñador que deberá aprender a programar; y es un computólogo que deberá saber analizar y encontrar datos con significado.[24]\\u200b \\n En la tesis doctoral de Benjamin Fry explicó que el proceso para comprender mejor a los datos comenzaba con una serie de números y el objetivo de responder preguntas sobre los datos, en cada fase del proceso que él propone (adquirir, analizar, filtrar, extraer, representar, refinar e interactuar), se requiere de diferentes enfoques especializados que aporten a una mejor comprensión de los datos. Entre los enfoques que menciona Fry están: ingenieros en sistemas, matemáticos, estadísticos, diseñadores gráficos, especialistas en visualización de la información y especialistas en interacciones hombre-máquina, mejor conocidos por sus siglas en inglés “HCI” (Human-Computer Interaction). Además, Fry afirmó que contar con diferentes enfoques especializados lejos de resolver el problema de entendimiento de datos, se convierte en parte del problema, ya que cada especialización conduce de manera aislada el problema y el camino hacia la solución se puede perder algo en cada transición del proceso.[25]\\u200b\\n en:Drew Conway en su página web explica con la ayuda de un diagrama de Venn, las principales habilidades que le dan vida y forma a la ciencia de datos, así como sus relaciones de conjuntos.\\n La ciencia de datos ha cobrado recientemente mucha importancia en nuestro acontecer como disciplina o profesión emergente (científico de datos) y se ha vuelto en foco de atención de cada vez más organizaciones a nivel mundial, tal como lo señaló el economista en jefe de Google, Hal Varian “El trabajo más sexy en los próximos 10 años será ser estadístico”, palabras sobre las que reflexionó  Thomas H. Davenport para publicar en el 2012 su artículo: Data Scientist: The Sexiest Job of the 21st Century\\n[26]\\u200b\\ndonde describe el perfil que debe tener el científico de datos es el híbrido de un hacker de datos, un analista, un comunicador y un consejero confiable, combinación extremadamente poderosa y poco común. Davenport, también señala que el científico de datos no se siente cómodo como se dice coloquialmente “con la correa corta”, es decir, debe tener la libertad de experimentar y explorar posibilidades. Además, Davenport en el mismo artículo presenta un decálogo de cómo encontrar el científico de datos que la organización necesita (ver página 74 del artículo).\\n El informe que publicó “McKinsey”[27]\\u200b\\nen el 2011 estimó que para el mundo de grandes datos en el que vivimos, espera que la demanda por talento experto en análisis de datos podría alcanzar de los 440,000 a 490,000 puestos de trabajo para el 2018.[cita\\xa0requerida]\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciencia_de_datos1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frecuencia de las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words(\"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciencia de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos_text = word_tokenize(ciencia_de_datos1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos_text = [x for x in ciencia_de_datos_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos_text = pd.DataFrame(ciencia_de_datos_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciencia_de_datos_text.to_csv('Palabras/ciencia_de_datos_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_text = word_tokenize(machine_learning1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_text = [x for x in machine_learning_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_text = pd.DataFrame(machine_learning_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_text.to_csv('Palabras/machine_learning_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aprendizaje_automatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprendizaje_automatico_text = word_tokenize(aprendizaje_automatico1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprendizaje_automatico_text = [x for x in aprendizaje_automatico_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprendizaje_automatico_text = pd.DataFrame(aprendizaje_automatico_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprendizaje_automatico_text.to_csv('Palabras/aprendizaje_automatico_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_text = word_tokenize(big_data1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_text = [x for x in big_data_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_text = pd.DataFrame(big_data_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_text.to_csv('Palabras/big_data_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inteligencia_artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_artificial_text = word_tokenize(inteligencia_artificial1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_artificial_text = [x for x in inteligencia_artificial_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_artificial_text = pd.DataFrame(inteligencia_artificial_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_artificial_text.to_csv('Palabras/inteligencia_artificial_text.csv', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analitica_de_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "analitica_de_datos_text = word_tokenize(analitica_de_datos1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "analitica_de_datos_text = [x for x in analitica_de_datos_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "analitica_de_datos_text = pd.DataFrame(analitica_de_datos_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "analitica_de_datos_text.to_csv('Palabras/analitica_de_datos_text.csv', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mineria_de_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineria_de_datos_text = word_tokenize(mineria_de_datos1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineria_de_datos_text = [x for x in mineria_de_datos_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineria_de_datos_text = pd.DataFrame(mineria_de_datos_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineria_de_datos_text.to_csv('Palabras/mineria_de_datos_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inteligencia_de_negocios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_de_negocios_text = word_tokenize(inteligencia_de_negocios1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_de_negocios_text = [x for x in inteligencia_de_negocios_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_de_negocios_text = pd.DataFrame(inteligencia_de_negocios_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inteligencia_de_negocios_text.to_csv('Palabras/inteligencia_de_negocios_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inteligencia_artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadistica_text = word_tokenize(estadistica1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadistica_text = [x for x in estadistica_text if x not in stop_word + list(string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadistica_text = pd.DataFrame(estadistica_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadistica_text.to_csv('Palabras/estadistica_text.txt', index= False, encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
