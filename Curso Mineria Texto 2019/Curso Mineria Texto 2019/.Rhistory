library(jsonlite) #sirve para hacer el paring del response
library(lubridate) #sirve para trabajar con formatos de fecha
library(bit64) #sirve para trabajar con enteros largos
library(data.table) #sirve para trabajar con big data
endpoint <- "http://webhose.io/filterWebContent"
apikey.webhose <- "fda0dba5-df49-4307-b420-9db26018797e"
format.v <- "json"
now <- Sys.time()
monthago <- now - days(30)
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
q.v_1 <- "estadistica colombia"
q.v_1 <- URLencode(q.v_1)
http1 <- paste0(endpoint, "?q=", q.v_1, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
response <- GET(http1,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
articles.text <- content(response, as = "text", encoding = "UTF-8")
articles.parsed <- content(response, as = "parsed")
articles <- fromJSON(articles.text)
articles.flt <- fromJSON(articles.text, flatten = T)
articles.df <- articles$posts
articles.flt.df <- articles.flt$posts
q.v <- "estadistica colombia"
library(data.table) #sirve para trabajar con big data
articles.flt.dt[, list(uuid, crawled)]
articles.flt.dt[, .(uuid, crawled)] #esto es equivalente
articles.flt.dt[, c("uuid", "crawled")] #esto es como se haría con data frames
articles.flt.dt[, c(uuid, crawled)] #esto con data frames daría error
articles.flt.dt[, new_col := NA]
articles.flt.dt$new_col <- NA #forma alterna al estilo data frame
view(articles.flt.dt)
articles.flt.dt[, new_col := NULL]
articles.flt.dt$new_col <- NULL
articles.flt.dt[, published_utc := ymd_hms(published)]
View(articles.flt.dt)
View(articles.flt.dt)
articles.flt.dt[, published_col := ymd_hms(published, tz = "America/Bogota")]
View(articles.flt.dt)
View(articles.flt.dt)
articles.flt.dt[, list(published_utc, published_col)]
articles.flt.dt[, mean(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[, max(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[, median(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[, quantile(thread.social.facebook.shares, na.rm = T, prob=0.75)]
articles.flt.dt[, quantile(thread.social.facebook.shares, na.rm = T, prob=0.85)]
articles.flt.dt[, quantile(thread.social.facebook.shares, na.rm = T, prob=0.25)]
articles.flt.dt[, mean(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[, quantile(thread.social.facebook.shares, na.rm = T, prob=0.15)]
articles.flt.dt[, quantile(thread.social.facebook.shares, na.rm = T, prob=0.05)]
articles.flt.dt[, min(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[, max(thread.social.facebook.shares, na.rm = T)]
articles.flt.dt[language=="spanish", mean(thread.social.facebook.shares)]
articles.flt.dt[, fb := thread.social.facebook.shares + thread.social.facebook.likes]
articles.flt.dt[, list(fb, thread.social.facebook.shares, thread.social.facebook.likes)]
articles.flt.dt <- articles.flt.dt[order(-fb)]
View(articles.flt.dt)
articles.flt.dt[, .N]
articles.flt.dt[language=="spanish", .N]
articles.flt.dt[, .N, by = thread.site_full]
articles.flt.dt[, id := .GRP, by = language]
View(articles.flt.dt)
View(articles.flt.dt)
View(articles.flt.dt)
articles.flt.dt[, id := .GRP, by = language]
View(articles.flt.dt)
View(articles.flt.dt)
x<- 4
log(x)
x %>% og()
x %>% log()
library(magrittr)
x %>% log()
round(log(x), 1)
exp(round(log(x), 1))
x %>%
log() %>%
round(1) %>%
exp()
library(dplyr) #libreria tidyverse que trabaja con manipulacion de dataframes
library(dplyr) #libreria tidyverse que trabaja con manipulacion de dataframes
exp(round(log(x), 1))
x %>%
log() %>%
round(1) %>%
exp()
library(dplyr) #libreria tidyverse que trabaja con manipulacion de dataframes
articles.flt.sl  <- articles.flt.dt %>%
select(uuid, crawled)
articles.flt.sl <- articles.flt.dt %>%
filter(language == "spanish")
head(articles.flt.sl$language)
library(magrittr)
x<- 4
log(x)
x %>% log()
round(log(x), 1)
x %>%
log() %>%
round(1)
exp(round(log(x), 1))
x %>%
log() %>%
round(1) %>%
exp()
library(dplyr) #libreria tidyverse que trabaja con manipulacion de dataframes
library(magrittr)
x<- 4
log(x)
x %>% log()
round(log(x), 1)
x %>%
log() %>%
round(1)
exp(round(log(x), 1))
x %>%
log() %>%
round(1) %>%
exp()
library(dplyr) #libreria tidyverse que trabaja con manipulacion de dataframes
articles.flt.sl  <- articles.flt.dt %>%
select(uuid, crawled)
articles.flt.sl <- articles.flt.dt %>%
filter(language == "spanish")
head(articles.flt.sl$language)
articles.flt.sl <- articles.flt.dt %>%
mutate(published_col = ymd_hms(published, tz = "America/Bogota"))
articles.flt.sl <- articles.flt.dt %>%
mutate(published_col = ymd_hms(published, tz = "America/Bogota"))
library(httr) #sirve para hacer el request
library(jsonlite) #sirve para hacer el paring del response
library(lubridate) #sirve para trabajar con formatos de fecha
library(bit64) #sirve para trabajar con enteros largos
library(data.table) #sirve para trabajar con big data
library(jsonlite) #sirve para hacer el paring del response
library(lubridate) #sirve para trabajar con formatos de fecha
library(bit64) #sirve para trabajar con enteros largos
library(data.table) #sirve para trabajar con big data
head(articles.flt.sl[, c("published", "published_col")])
articles.flt.count <- articles.flt.dt %>%
count()
articles.flt.count
articles.flt.dt %>%
group_by(language) %>%
count()
articles.flt.sum <- articles.flt.dt %>%
summarise(shares_tot = mean(thread.social.facebook.shares))
articles.flt.dt %>%
summarise(shares_tot = mean(thread.social.facebook.shares))
articles.flt.sum <- articles.flt.dt %>%
group_by(thread.site_full) %>%
summarise(result_tot = mean(thread.social.facebook.shares))
articles.flt.dt %>%
group_by(thread.site_full) %>%
summarise(result_tot = mean(thread.social.facebook.shares))
articles.flt.sum
articles.flt.sl <- articles.flt.dt %>%
arrange(uuid)
library(dplyr)
system.time(icfes.dt[order(estu_consecutivo)])
system.time(icfes.dt %>%
[order(icfes.df$estu_comnsecutivo).])
q.v <- paste0(q.v, " language:", language.v)
q.v <- "estadistica colombia"
language.v <- "spanish"
q.v <- paste0(q.v, " language:", language.v)
q.v <- URLencode(q.v, reserved = T, repeated = T)
q.v
http <- paste0(endpoint, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v, "&sort=", sort.v,  "&from=", from.v)
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
nout <- 100
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
response <- GET(http,
add_headers("Accept" = "text/plain"))
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
articles.text <- content(response, as = "text", encoding = "UTF-8")
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt.dt <- as.data.table(articles.flt[["posts"]])
articles.flt.dt[, .N, by = language]
articles.flt.next <- articles.flt[["next"]]
articles.flt.dt <- as.data.table(articles.flt.df)
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
endpoint <- "http://webhose.io/filterWebContent?token=fda0dba5-df49-4307-b420-9db26018797e&format=json&ts=1557952718853&sort=crawled&q=estadistica%20language%3Aspanish"
endpoint <- "http://webhose.io/filterWebContent?token=fda0dba5-df49-4307-b420-9db26018797e&format=json&sort=crawled&q=digital%20colombia"
endpoint <- "http://webhose.io/filterWebContent"
library(httr) #sirve para hacer el request
library(jsonlite) #sirve para hacer el paring del response
library(lubridate) #sirve para trabajar con formatos de fecha
library(bit64) #sirve para trabajar con enteros largos
library(data.table) #sirve para trabajar con big data
endpoint <- "http://webhose.io/filterWebContent"
endpoint1 <- "http://webhose.io/filterWebContent"
q.v <- "Transformacion Colombia"
q.v <- "Transformacion Colombia"
apikey.webhose <- "fda0dba5-df49-4307-b420-9db26018797e"
format.v <- "json"
q.v <- URLencode(q.v)
now <- Sys.time()
monthago <- now - days(30)
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
http <- paste0(endpoint1, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
response <- GET(http,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
q.v <- "Transformacion Digital Colombia"
format.v <- "json"
q.v <- URLencode(q.v)
now <- Sys.time()
now
monthago <- now - days(30)
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
http <- paste0(endpoint1, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
response <- GET(http,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
q.v <- "Transformacion and Digital and Colombia"
apikey.webhose <- "fda0dba5-df49-4307-b420-9db26018797e"
format.v <- "json"
q.v <- URLencode(q.v)
now <- Sys.time()
monthago <- now - days(30)
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
http <- paste0(endpoint1, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
response <- GET(http,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
articles.parsed <- content(response, as = "parsed")
articles <- fromJSON(articles.text)
articles.flt <- fromJSON(articles.text, flatten = T)
q.v <- "Transformacion AND Digital AND Colombia"
articles.flt$totalResults
sort.v <- "relevancy"
articles.text <- content(response, as = "text", encoding = "UTF-8")
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt.df <- articles.flt[["posts"]]
articles.flt.tr <- articles.flt[["totalResults"]]
articles.flt.mra <- articles.flt[["moreResultsAvailable"]]
articles.flt.mra
articles.flt.next <- articles.flt[["next"]]
articles.flt.next
articles.flt.dt <- as.data.table(articles.flt.df)
articles.flt.dt
nout <- 100
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
View(articles.flt.dt)
View(articles.flt.df)
str(articles.flt.df)
articles.flt.dt[, .N]
articles.flt.dt[language=="spanish", .N]
articles.flt.dt[, .N, by = thread.site_full]
View(articles.flt.df)
articles.flt.dt[, .N, by = thread.site_type]
nout <- 100
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
articles.flt.dt[, .N]
articles.flt.dt[, .N, by = thread.site_country]
articles.flt.dt[, .N, by = thread.country]
articles.flt.dt[, .N, by = c(thread.country,thread.site_type)]
articles.flt.dt[, .N, by = thread.country]
articles.flt.dt[, .N, by = thread.site_country]
articles.flt.dt[, .N, by = c("thread.country","thread.site_type")]
endpoint1 <- "http://webhose.io/filterWebContent"
q.v <- "Transformacion Digital AND Colombia"
apikey.webhose <- "fda0dba5-df49-4307-b420-9db26018797e"
format.v <- "json"
q.v <- URLencode(q.v)
now <- Sys.time()
now
monthago <- now - days(30)
monthago
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
ts.v
http <- paste0(endpoint1, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
http
response <- GET(http,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
articles.parsed <- content(response, as = "parsed")
articles <- fromJSON(articles.text)
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt$totalResults
sort.v <- "relevancy"
articles.text <- content(response, as = "text", encoding = "UTF-8")
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt.df <- articles.flt[["posts"]]
articles.flt.tr <- articles.flt[["totalResults"]]
articles.flt.mra <- articles.flt[["moreResultsAvailable"]]
articles.flt.next <- articles.flt[["next"]]
articles.flt.dt <- as.data.table(articles.flt.df)
nout <- 100
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
articles.flt.dt[, .N]
articles.flt.dt[language=="spanish", .N]
articles.flt.dt[, .N, by = c("thread.country","thread.site_type")]
articles.flt.dt[, .N, by = thread.site_type]
articles.flt.dt[, .N, by = thread.country]
library(rgl)
plot3d(xm[,1],xm[,3],xm[,2])
play3d(spin3d(plot3d(xm[,1],xm[,3],xm[,2])), duration=10)
library(rgl)
plot3d(xm[,1],xm[,3],xm[,2])
play3d(spin3d(plot3d(xm[,1],xm[,3],xm[,2])), duration=10)
x=seq(-3,3,length=100)
y=seq(-3,3,length=100)
supe=function(x,y) x^2+y^2+x*y+1
z=outer(x, y, supe)
par(mfrow=c(1,3))
persp(x,y,z,theta = 15, phi=-10,col="cyan")
contour(x,y,z,add=T, col="black")
par(mfrow=c(1,1))
persp(x,y,z,theta = 15, phi=-10,col="cyan")
contour(x,y,z,add=T, col="black")
contour(x,y,z,add=T, col="black")
library(webhouse)
library(webhose)
install.packages("webhose")
install.packages("devtools")
library(devtools)
install_github(webhose)
install_git(webhose)
install_git("hrbrmstr/webhose")
install_github("hrbrmstr/webhose")
library(httr) #sirve para hacer el request
library(jsonlite) #sirve para hacer el paring del response
library(lubridate) #sirve para trabajar con formatos de fecha
library(bit64) #sirve para trabajar con enteros largos
library(data.table) #sirve para trabajar con big data
endpoint1 <- "http://webhose.io/filterWebContent"
q.v <- "Transformacion Digital AND Colombia"
apikey.webhose <- "fda0dba5-df49-4307-b420-9db26018797e"
format.v <- "json"
q.v <- URLencode(q.v)
now <- Sys.time()
monthago <- now - days(30)
ts.v <- as.integer64(as.numeric(monthago)*1000, digits=15)
http <- paste0(endpoint1, "?q=", q.v, "&token=", apikey.webhose, "&format=",
format.v, "&ts=", ts.v)
response <- GET(http,
add_headers("Accept" = "text/plain"))
status_code(response)
http_error(response)
headers(response)
articles.parsed <- content(response, as = "parsed")
articles <- fromJSON(articles.text)
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt$totalResults
sort.v <- "relevancy"
articles.text <- content(response, as = "text", encoding = "UTF-8")
articles.flt <- fromJSON(articles.text, flatten = T)
articles.flt.df <- articles.flt[["posts"]]
articles.flt.tr <- articles.flt[["totalResults"]]
articles.flt.mra <- articles.flt[["moreResultsAvailable"]]
articles.flt.next <- articles.flt[["next"]]
articles.flt.next
articles.flt.dt <- as.data.table(articles.flt.df)
nout <- 100
while(nout == 100){
http <- paste0("http://webhose.io", articles.flt.next)
response <- GET(http,
add_headers("Accept" = "text/plain"))
articles.text.tmp <- content(response, as = "text", encoding = "UTF-8")
articles.flt.tmp <- fromJSON(articles.text.tmp, flatten = T)
articles.flt.dt.tmp <- as.data.table(articles.flt.tmp[["posts"]])
articles.flt.next <- articles.flt.tmp[["next"]]
nout <- nrow(articles.flt.dt.tmp)
l <- list(articles.flt.dt, articles.flt.dt.tmp)
articles.flt.dt <- rbindlist(l, use.names = T)
articles.flt.mra <- articles.flt.tmp[["moreResultsAvailable"]]
hd <- headers(response)
apicall <- hd[["x-webhose-requests-left"]]
msg <- paste0("Articulos restantes: ", articles.flt.mra, " - Requests restantes: ", apicall)
print(msg)
}
articles.flt.dt[, .N]
articles.flt.dt[language=="spanish", .N]
articles.flt.dt[, .N, by = thread.site_type]
articles.flt.dt[, .N, by = thread.country]
articles.flt.dt[, .N, by = c("thread.country","thread.site_type")]
save(ejer1)
save("ejer1")
save(articles.flt.dt,"ejer1.RData")
save(articles.flt.dt,"ejer1.rData")
save(articles.flt.dt,file="ejer1.rData")
save.image("todoejem1.RData")
setwd("E:/Curso Mineria Texto 2019")
